{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估模型\n",
    "---\n",
    "\n",
    "## 概要\n",
    "---\n",
    "\n",
    "这里我们将执行两个建模任务：回归和分类。我们将展示如何 在TensorFlow 算法中评估模型。\n",
    "\n",
    "## 回归模型\n",
    "---\n",
    "\n",
    "回归模型来自上一节。我们将生成以 Normal（mean = 1，sd = 0.1）和目标数据或重复10.0值分发的输入数据。该模型将优化乘法因子（理论上= 10）来预测目标数据。\n",
    "\n",
    "## 分类模型\n",
    "---\n",
    "\n",
    "分类模型将为 normal(mean = -1, sd = 1) 的一半值和 normal(mean = 2, sd = 1) 的一半值，在这分布中会有一些重叠。分类模型将对预测中间点进行优化，中间点可以既是分类界限。\n",
    "\n",
    "## 大纲\n",
    "---\n",
    "\n",
    "这个想法是我们想将标记的数据集分成训练和测试集。然后我们对测试集进行训练，并查看测试集的准确性。\n",
    "\n",
    "## 分类结果\n",
    "---\n",
    "\n",
    "这是分类结果可视化的直方图：\n",
    "![]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正文\n",
    "---\n",
    "\n",
    "这段代码将实现两个模型。第一个是一个简单的回归模型，我们将在训练期间展示如何调用损失函数MSE，并在测试和训练集之后输出。\n",
    "\n",
    "第二个模型将是一个简单的分类模型。我们还将展示如何打印测试和训练集分类的百分比。\n",
    "\n",
    "### 回归模型\n",
    "\n",
    "对于回归模型，我们将从 normal（mean = 1，sd = 0.1）生成100个随机样本。目标将是一个大小为100的数组，目标值为10.0。\n",
    "\n",
    "我们将拟合线性模型 $y = A \\cdot x$（没有 y 截距）。 A的理论值为10.0。\n",
    "\n",
    "加载必要的库并重置计算图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "启动图会话："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "声明批量大小（batch size）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成回归数据\n",
    "\n",
    "这里我们生成回归所需的数据。我们还指定必要的占位符。\n",
    "\n",
    "然后我们将数据分解成 80-20 训练-测试切分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 生成数据\n",
    "x_vals = np.random.normal(1, 0.1, 100)\n",
    "y_vals = np.repeat(10., 100)\n",
    "x_data = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "# 切分数据为 训练/测试集 = 80%/20%\n",
    "train_indices = np.random.choice(len(x_vals), round(len(x_vals) * 0.8), replace=False)\n",
    "test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\n",
    "x_vals_train = x_vals[train_indices]\n",
    "x_vals_test = x_vals[test_indices]\n",
    "y_vals_train = y_vals[train_indices]\n",
    "y_vals_test = y_vals[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型变量和操作\n",
    "\n",
    "我们创建模型变量 A 和乘法操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 创建模型变量 A\n",
    "A = tf.Variable(tf.random_normal(shape=[1, 1]))\n",
    "\n",
    "# 添加操作到图\n",
    "my_output = tf.matmul(x_data, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失，优化函数，和变量初始化\n",
    "\n",
    "我们使用 L2 损失函数，标准梯度下降优化，学习率为0.02。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 添加 L2 损失函数到图\n",
    "loss = tf.reduce_mean(tf.square(my_output - y_target))\n",
    "\n",
    "# 创建优化器\n",
    "my_opt = tf.train.GradientDescentOptimizer(0.02)\n",
    "train_step = my_opt.minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行回归\n",
    "\n",
    "我们通过培训步骤迭代100次，每次选择一批随机数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #25 A = [[ 6.70642376]]\n",
      "Loss = 12.4879\n",
      "Step #50 A = [[ 8.85753441]]\n",
      "Loss = 2.52929\n",
      "Step #75 A = [[ 9.65153217]]\n",
      "Loss = 1.24485\n",
      "Step #100 A = [[ 9.94890499]]\n",
      "Loss = 1.15033\n"
     ]
    }
   ],
   "source": [
    "# Run Loop\n",
    "for i in range(100):\n",
    "    rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n",
    "    rand_x = np.transpose([x_vals_train[rand_index]])\n",
    "    rand_y = np.transpose([y_vals_train[rand_index]])\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    if (i+1)%25==0:\n",
    "        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)))\n",
    "        print('Loss = ' + str(sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估回归模型\n",
    "\n",
    "对回归模型评估，我们将运行训练和测试集的损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on test:0.68\n",
      "MSE on train:1.17\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy (loss) on test set\n",
    "mse_test = sess.run(loss, feed_dict={x_data: np.transpose([x_vals_test]), y_target: np.transpose([y_vals_test])})\n",
    "mse_train = sess.run(loss, feed_dict={x_data: np.transpose([x_vals_train]), y_target: np.transpose([y_vals_train])})\n",
    "print('MSE on test:' + str(np.round(mse_test, 2)))\n",
    "print('MSE on train:' + str(np.round(mse_train, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类例子\n",
    "\n",
    "对分类模型，我们生成如下数据：\n",
    "\n",
    "输入数据是从 normal(mean = -1, sd = 1) 和 normal(mean = 1, sd = 1) 中各采样 50 个数据。\n",
    "\n",
    "目标数据是 50 个 0 和 50 个 1。\n",
    "\n",
    "我们拟合二进制分类模型：\n",
    "\n",
    "- 如果 $sigmoid(x + A) < 0.5$，我们推断为 0\n",
    "- 吐过 $sigmoid(x + A) >= 0.5$，我们推断为 1\n",
    "\n",
    "理论上 A 应该是：\n",
    "\n",
    "$$- \\frac{mean1 + mean2}{2} = 0$$\n",
    "\n",
    "好了，现在重置图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建图会话："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "声明批量大小："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成分类数据和目标数据\n",
    "\n",
    "我们如上所述生成分类数据。然后我们创建必要的占位符。\n",
    "\n",
    "然后，我们切分数据为 80-20 训练/测试集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create data\n",
    "x_vals = np.concatenate((np.random.normal(-1, 1, 50), np.random.normal(2, 1, 50)))\n",
    "y_vals = np.concatenate((np.repeat(0., 50), np.repeat(1., 50)))\n",
    "x_data = tf.placeholder(shape=[1, None], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[1, None], dtype=tf.float32)\n",
    "\n",
    "# Split data into train/test = 80%/20%\n",
    "train_indices = np.random.choice(len(x_vals), round(len(x_vals)*0.8), replace=False)\n",
    "test_indices = np.array(list(set(range(len(x_vals))) - set(train_indices)))\n",
    "x_vals_train = x_vals[train_indices]\n",
    "x_vals_test = x_vals[test_indices]\n",
    "y_vals_train = y_vals[train_indices]\n",
    "y_vals_test = y_vals[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型变量和操作\n",
    "\n",
    "我们创建模型变量 A 和模型操作，它是将 A 添加到输入数据。请注意，我们不将 sigmoid() 函数放在这里，因为它将被包含在损失函数中。这也意味着对于预测，我们将需要包含 sigmoid 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create variable (one model parameter = A)\n",
    "A = tf.Variable(tf.random_normal(mean=10, shape=[1]))\n",
    "\n",
    "# Add operation to graph\n",
    "# Want to create the operstion sigmoid(x + A)\n",
    "# Note, the sigmoid() part is in the loss function\n",
    "my_output = tf.add(x_data, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失，优化函数，和变量初始化\n",
    "\n",
    "损失函数选用 sigmoid-cross-entropy。我们使用 reduce_mean() 来封装损失函数以便在全批次数据中减少 sigmoid-cross-entropy。\n",
    "\n",
    "我们使用的优化函数仍是标准梯度下降优化，学习率为0.05。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add classification loss (cross entropy)\n",
    "xentropy = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=my_output, labels=y_target))\n",
    "\n",
    "# Create Optimizer\n",
    "my_opt = tf.train.GradientDescentOptimizer(0.05)\n",
    "train_step = my_opt.minimize(xentropy)\n",
    "\n",
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行分类\n",
    "\n",
    "我们迭代 1800 次分类训练操作，并且每200次迭代一次打印出 A 值和损失值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #200 A = [ 7.01122999]\n",
      "Loss = 3.31835\n",
      "Step #400 A = [ 2.73941112]\n",
      "Loss = 0.354624\n",
      "Step #600 A = [ 0.50843418]\n",
      "Loss = 0.316609\n",
      "Step #800 A = [-0.10985172]\n",
      "Loss = 0.330854\n",
      "Step #1000 A = [-0.23218325]\n",
      "Loss = 0.299426\n",
      "Step #1200 A = [-0.23459852]\n",
      "Loss = 0.260422\n",
      "Step #1400 A = [-0.26495484]\n",
      "Loss = 0.227307\n",
      "Step #1600 A = [-0.2499817]\n",
      "Loss = 0.206538\n",
      "Step #1800 A = [-0.29281732]\n",
      "Loss = 0.273244\n"
     ]
    }
   ],
   "source": [
    "# Run loop\n",
    "for i in range(1800):\n",
    "    rand_index = np.random.choice(len(x_vals_train), size=batch_size)\n",
    "    rand_x = [x_vals_train[rand_index]]\n",
    "    rand_y = [y_vals_train[rand_index]]\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    if (i+1)%200==0:\n",
    "        print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)))\n",
    "        print('Loss = ' + str(sess.run(xentropy, feed_dict={x_data: rand_x, y_target: rand_y})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估分类结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 0.925\n",
      "Accuracy on test set: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIhIxStwiIhGjxC0iEjFK3CIiEfN/F8suid60Tt4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1115adbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate Predictions on test set\n",
    "y_prediction = tf.squeeze(tf.round(tf.nn.sigmoid(tf.add(x_data, A))))\n",
    "correct_prediction = tf.equal(y_prediction, y_target)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "acc_value_test = sess.run(accuracy, feed_dict={x_data: [x_vals_test], y_target: [y_vals_test]})\n",
    "acc_value_train = sess.run(accuracy, feed_dict={x_data: [x_vals_train], y_target: [y_vals_train]})\n",
    "print('Accuracy on train set: ' + str(acc_value_train))\n",
    "print('Accuracy on test set: ' + str(acc_value_test))\n",
    "\n",
    "# Plot classification result\n",
    "A_result = -sess.run(A)\n",
    "bins = np.linspace(-5, 5, 50)\n",
    "plt.hist(x_vals[0:50], bins, alpha=0.5, label='N(-1,1)', color='gray')\n",
    "plt.hist(x_vals[50:100], bins[0:50], alpha=0.5, label='N(2,1)', color='red')\n",
    "plt.plot((A_result, A_result), (0, 8), 'k--', linewidth=3, label='A = '+ str(np.round(A_result, 2)))\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Binary Classifier, Accuracy=' + str(np.round(acc_value_test, 2)))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
